sources:  
  internal_metrics:
    type: internal_metrics
    scrape_interval_secs: 10

  internal_logs:
    type: internal_logs
    pid_key: ""

  host_metrics:
    type: host_metrics
    scrape_interval_secs: 10
    collectors: [cpu, disk, load, memory, network, host]

  kubernetes_logs:
    type: kubernetes_logs
    glob_minimum_cooldown_ms: 5000
    ignore_older_secs: 3600
    extra_label_selector: "app!=vector" # vector logs handled internally
    insert_namespace_fields: false
    ingestion_timestamp_field: ""
    namespace_annotation_fields:
      namespace_labels: ""
    node_annotation_fields:
      node_labels: ""

  smart_home:
    type: vector
    address: 0.0.0.0:8222

  envoy_metrics:
    type: prometheus_scrape
    endpoints:
      - http://envoy-gateway.envoy.svc.cluster.local:19001/metrics
    scrape_interval_secs: 10

  coredns_metrics:
    type: prometheus_scrape
    endpoints:
      - http://kube-dns.kube-system.svc.cluster.local:9153/metrics
    scrape_interval_secs: 10

  thermal:
    type: exec
    command: ["cat", "/sys/class/thermal/thermal_zone0/temp"]
    mode: scheduled
    scheduled:
      exec_interval_secs: 5
    decoding:
      codec: bytes

transforms:
  format_thermal:
    type: remap
    inputs:
      - thermal
    source: |
      # truncate all but first 2 characters, and convert to int
      . = {
        "temperature": to_int!(truncate!(.message, limit: 2)),
        "node": get_env_var!("VECTOR_SELF_NODE_NAME")
      } 

  thermal_to_metric:
    type: log_to_metric
    inputs:
      - format_thermal
    metrics:
      - type: gauge
        name: thermal
        field: temperature
        tags:
          node: "{{node}}"

  label_envoy_metrics:
    type: remap
    inputs: [envoy_metrics]
    source: .namespace = "envoy"

  label_coredns_metrics:
    type: remap
    inputs: [coredns_metrics]
    source: .namespace = "coredns"

  tag_host_metrics: 
    # Cleanup host metrics
    type: remap
    inputs: 
      - host_metrics
    drop_on_error: true
    source: |
      del(.tags.mode)
      del(.tags.cpu)
      del(.tags.collector)
      del(.tags.device)

      .tags.node_name = get_env_var!("VECTOR_SELF_NODE_NAME")

  smart_home_router:
    # Route logs from smart home by type
    type: route
    inputs:
      - smart_home
    route:
      metrics: "!exists(.log)"
      logs: exists(.log)

  remap_k8s_logs:
    # Sanitise all k8s logs before further processing
    type: remap
    inputs:
      - kubernetes_logs
    source: |
      .container = .kubernetes.container_name
      .namespace = .kubernetes.pod_namespace
      .node = get_env_var!("VECTOR_SELF_NODE_NAME")
    
      # align 'app' labelling for better filtering in Grafana
      # the 'k8s-app' label is used by some K3s packaged components
      .app = 
        .kubernetes.pod_labels."app.kubernetes.io/name" ||
        .kubernetes.pod_labels.app ||
        .kubernetes.pod_labels."k8s-app"

      # remove all unneeded kubernetes labels and fields
      del(.kubernetes)
      del(.stream)
      del(.file)
      
  k8s_log_router:
    # Route k8s logs by format or application
    type: route
    inputs:
      - remap_k8s_logs
    route:
      klog: includes(["metrics-server", "local-path-provisioner", "cert-manager-controller", "cert-manager-cainjector", "cert-manager-webhook", "node-driver-registrar", "secrets-store"], .container)
      json: includes(["grafana-sc-datasources", "grafana-sc-dashboard", "notifications-controller"], .container)
      key_value: includes(["grafana", "influxdb2", "registry", "application-controller", "applicationset-controller", "repo-server", "server", "trust-manager", "reloader-reloader"], .container)
      vault: includes(["vault", "sidecar-injector", "vault-csi-provider"], .container)
      vault-secrets-operator: .app == "vault-secrets-operator"
      envoy: .container == "envoy"
      envoy_gateway: .container == "envoy-gateway"
      flux: .namespace == "flux-system"
      kyverno: .namespace == "kyverno"


  parse_klog:
    # Parser for Kubernetes internal components
    type: remap
    inputs:
      - k8s_log_router.klog
    source: |
      parsed, err = parse_klog(.message)

      if err == null {
        .timestamp = del(parsed.timestamp)
        .level = del(parsed.level)

        # FORMAT: '<message> <other=fields>, ...'
        .message = join([del(parsed.message), encode_logfmt(parsed)], " ") ?? .message

      } else {
        log(
          {
            "message": "Error parsing event as klog",
            "event": .message,
            "error": err, 
            "source_app": .app,
            "source_container": .container,
            "source_namespace": .namespace
          },
          level: "warn"
        )
      }

  parse_key_value:
    #Â Parse events from key-value format
    # As standalone keys are accepted, most space-separated strings will be parsed without error.
    # Encoding them back into logfmt alphabetises the fields, meaning these strings often return scrambled.
    # So, only use this parser where it is relatively certain events will be in key-value or logfmt format.
    type: remap
    inputs:
      - k8s_log_router.key_value
    source: |    
      parsed, err = parse_key_value(.message)

      if err == null {
        .timestamp = del(parsed.timestamp) || del(parsed.time) || del(parsed.ts) || del(parsed.t) || .timestamp
        .level = del(parsed.level) || del(parsed.lvl)

        # FORMAT: '<message> <other=fields>, ...'
        message = del(parsed.message) || del(parsed.msg) || ""
        message = join([to_string!(message), encode_logfmt(parsed)], " ") ?? .message
        .message = strip_whitespace!(message)

      } else {
        log(
          {
            "message": "Error parsing event as key-value",
            "event": .message,
            "error": err, 
            "source_app": .app,
            "source_container": .container,
            "source_namespace": .namespace
          },
          level: "warn"
        )
      }

  parse_json:
    # Parse events from JSON format
    type: remap
    inputs:
      - k8s_log_router.json
      - k8s_log_router.flux
      - k8s_log_router.vault-secrets-operator
      - k8s_log_router.kyverno
    source: |
      # The 'message' field is always a string from stdout, so this always succeeds
      message_string = to_string(.message) ?? "" 

      # Verify if the string is JSON before parsing, because parsing a non-JSON string alphabetises space-separated words
      if is_json(message_string) {
        parsed, err = parse_json(message_string)
        
        if err == null {
          .timestamp = del(parsed.timestamp) || del(parsed.time) || del(parsed.ts) || del(parsed.t) || .timestamp
          .level = del(parsed.level) || del(parsed.lvl)

          # FORMAT: '<message> <other=fields>, ...'
          message = del(parsed.message) || del(parsed.msg) || ""
          message = join([to_string!(message), encode_logfmt!(parsed)], " ") ?? .messsage
          .message = strip_whitespace!(message)

        } else {
          log(
            {
              "message": "Error parsing event as JSON", 
              "error": err,
              "event": .message,
              "source_app": .app,
              "source_container": .container,
              "source_namespace": .namespace
            }, 
            level: "warn"
          )
        }
      } else {
        log(
          {
            "message": "Event is not valid JSON", 
            "event": .message,
            "source_app": .app,
            "source_container": .container,
            "source_namespace": .namespace
          }, 
          level: "warn"
        )
      }

  parse_vault:
    # parse HashiCorp format, or klog in case of unhandled errors
    # https://support.hashicorp.com/hc/en-us/articles/360000995548-Audit-and-Operational-Log-Details#:~:text=Vault%20Operational%20Log%20Details
    type: remap
    inputs:
      - k8s_log_router.vault
    source: |
      parsed = 
        parse_grok(.message, s'%%{TIMESTAMP_ISO8601:timestamp} \[%%{LOGLEVEL:level}\]%%{SPACE}%%{GREEDYDATA:message}') ??
        parse_klog(.message) ?? 
        {}

      .timestamp = del(parsed.timestamp) || .timestamp
      .level = del(parsed.level)
      message = del(parsed.message) || ""

      # FORMAT: '<message> <other=fields>, ...'
      .message = join([to_string!(message), encode_logfmt(parsed)], " ") ?? .message

  parse_envoy:
    # Parser for Envoy Gateway access log format:
    # https://gateway.envoyproxy.io/docs/tasks/observability/proxy-accesslog/#default-access-log
    type: remap
    inputs:
      - k8s_log_router.envoy
    source: |
      parsed = parse_json(.message) ?? {}

      # derive log level from response code if it exists
      if exists(parsed.response_code) {
        .level = "INFO"
        
        parsed.response_code = int!(parsed.response_code)

        if parsed.response_code >= 500 {
          .level = "ERROR"
        } else if parsed.response_code >= 400 {
          .level = "WARNING"
        }
      }

  parse_envoy_gateway:
    # Parser for Envoy Gateway access log format:
    # https://gateway.envoyproxy.io/docs/tasks/observability/proxy-accesslog/#default-access-log
    type: remap
    inputs:
      - k8s_log_router.envoy_gateway
    source: |
      parsed = 
        parse_grok(.message, "%%{TIMESTAMP_ISO8601:timestamp}%%{SPACE}%%{LOGLEVEL:level}%%{SPACE}%%{GREEDYDATA:message}") ??
        {}

      .timestamp = del(parsed.timestamp) || .timestamp
      .level = del(parsed.level)
      message = del(parsed.message) || ""

      # FORMAT: '<message> <other=fields>, ...'
      .message = join([to_string!(message), encode_logfmt(parsed)], " ") ?? .message

  parse_vector:
    # Parse Vector internal logs
    type: remap
    inputs:
      - internal_logs
    source: |
      # Create fresh object to output, due to number of fields emitted
      # This contains any tags or filterable fields, all others are encoded into the 'message' field
      output.timestamp = del(.timestamp)
      output.level = del(.metadata.level)
      output.node = get_env_var!("VECTOR_SELF_NODE_NAME")
      output.app = output.container = output.namespace = "vector"

      # include component id in log message
      .component_id = del(.vector.component_id)

      # remove any unnecessary fields
      del(.source_type)
      del(.metadata)
      del(.vector)
      del(%host)

      # FORMAT: <message> <other>=<fields>...
      output.message = join!([to_string!(del(.message)), encode_logfmt(compact(.))], " ")

      . = output


sinks:
  metrics:
    type: influxdb_metrics
    inputs: 
      - internal_metrics
      - tag_host_metrics
      - thermal_to_metric
      - smart_home_router.metrics
      - label_* # all metrics labellers
    endpoint: ${INFLUXDB_ADDR}
    bucket: data
    org: homelab
    token: ${INFLUXDB_TOKEN}
    batch:
      max_events: 2500
    buffer:
      max_events: 25000
    request:
      retry_attempts: 5
    tls:
      server_name: ${INFLUXDB_SERVER_NAME}
      ca_file: /etc/ssl/certs/ca.crt
      verify_certificate: true
      verify_hostname: true

  logs:
    # Kubernetes pod logs
    type: influxdb_logs
    measurement: k8s_logs
    inputs: 
      - k8s_log_router._unmatched
      - parse_* # all log parsers
    endpoint: ${INFLUXDB_ADDR}
    bucket: data
    org: homelab
    token: ${INFLUXDB_TOKEN}
    batch:
      max_events: 1000
    buffer:
      max_events: 10000
    tags: [level, container, namespace, app, node]
    request:
      retry_attempts: 5
    tls:
      server_name: ${INFLUXDB_SERVER_NAME}
      ca_file: /etc/ssl/certs/ca.crt
      verify_certificate: true
      verify_hostname: true

  docker_logs:
    # Logs from the smart home Docker containers
    type: influxdb_logs
    measurement: docker_logs
    inputs: 
      - smart_home_router.logs
      - smart_home_router._unmatched
    endpoint: ${INFLUXDB_ADDR}
    bucket: data
    org: homelab
    token: ${INFLUXDB_TOKEN}
    batch:
      max_events: 1000
    buffer:
      max_events: 10000
    tags: [level, container, node, tag]
    request:
      retry_attempts: 5
    tls:
      server_name: ${INFLUXDB_SERVER_NAME}
      ca_file: /etc/ssl/certs/ca.crt
      verify_certificate: true
      verify_hostname: true
